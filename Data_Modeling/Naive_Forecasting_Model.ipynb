{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75838962-f12c-4622-8972-b38cee46189e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdbe50f-f830-4740-8605-62ab90ac21e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the relative path to the Dataset folder\n",
    "dataset_path = '../Datasets/df_aggregated_month_populated_btp_core.parquet'\n",
    "\n",
    "# Read DataFrame from Parquet\n",
    "df_aggregated_month_populated_btp_core = pd.read_parquet(dataset_path, engine='pyarrow')\n",
    "print(df_aggregated_month_populated_btp_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd1fed11-ffdd-4710-a6c4-d56c4673241d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First test\n",
    "# Sort the data by DATE to ensure proper ordering\n",
    "df_aggregated_month_populated_btp_core = df_aggregated_month_populated_btp_core.sort_values(by=['DATE', 'CUSTOMER_ID'])\n",
    "\n",
    "# Creating a naive forecast (shifting TOTAL_CONSUMPTION_SUM by 1 to predict next month based on the previous month)\n",
    "df_aggregated_month_populated_btp_core['NAIVE_PREDICTION'] = df_aggregated_month_populated_btp_core.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(1)\n",
    "\n",
    "# Dropping the first row of each customer where no previous data exists for prediction\n",
    "df_naive = df_aggregated_month_populated_btp_core.dropna(subset=['NAIVE_PREDICTION'])\n",
    "\n",
    "# Extract actual values and naive predictions\n",
    "y_true = df_naive['TOTAL_CONSUMPTION_SUM']\n",
    "y_pred = df_naive['NAIVE_PREDICTION']\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Exclude zero actual values for MAPE calculation\n",
    "non_zero_mask = y_true != 0\n",
    "y_true_non_zero = y_true[non_zero_mask]\n",
    "y_pred_non_zero = y_pred[non_zero_mask]\n",
    "\n",
    "# Calculate MAPE (without dividing by zero)\n",
    "mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(f'R²: {r2}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MAPE: {mape}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e7e1dab-e830-4e75-8839-4a93a6166e62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model for each horizon\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Exclude zero actual values for MAPE calculation\n",
    "    non_zero_mask = y_true != 0\n",
    "    y_true_non_zero = y_true[non_zero_mask]\n",
    "    y_pred_non_zero = y_pred[non_zero_mask]\n",
    "\n",
    "    # Calculate MAPE (without dividing by zero)\n",
    "    mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "\n",
    "    # Return the calculated metrics\n",
    "    return r2, rmse, mae, mape\n",
    "\n",
    "# Initialize dictionaries to store metrics for averaging across horizons\n",
    "metrics = {'H1': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []},\n",
    "           'H2': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []},\n",
    "           'H3': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []}}\n",
    "\n",
    "# Apply naive forecast using TimeSeriesSplit\n",
    "for train_index, test_index in tscv.split(df_aggregated_month_populated_btp_core):\n",
    "    train = df_aggregated_month_populated_btp_core.iloc[train_index].copy()  # Create a copy of the train DataFrame\n",
    "    test = df_aggregated_month_populated_btp_core.iloc[test_index].copy()    # Create a copy of the test DataFrame\n",
    "\n",
    "    # Shift TOTAL_CONSUMPTION_SUM by 1, 2, and 3 to predict next months based on previous months\n",
    "    for h in range(1, 4):\n",
    "        train[f'NAIVE_PREDICTION_H{h}'] = train.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(h)\n",
    "        test[f'NAIVE_PREDICTION_H{h}'] = test.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(h)\n",
    "\n",
    "    # Evaluate each horizon\n",
    "    for h in range(1, 4):\n",
    "        # Drop rows with NaN predictions\n",
    "        test_naive = test.dropna(subset=[f'NAIVE_PREDICTION_H{h}'])\n",
    "\n",
    "        # Extract true and predicted values for testing\n",
    "        y_true_test = test_naive['TOTAL_CONSUMPTION_SUM']\n",
    "        y_pred_test = test_naive[f'NAIVE_PREDICTION_H{h}']\n",
    "\n",
    "        # Calculate metrics for the current split and horizon\n",
    "        r2, rmse, mae, mape = calculate_metrics(y_true_test, y_pred_test)\n",
    "\n",
    "        # Append metrics to the corresponding horizon lists\n",
    "        metrics[f'H{h}']['r2_scores'].append(r2)\n",
    "        metrics[f'H{h}']['rmses'].append(rmse)\n",
    "        metrics[f'H{h}']['maes'].append(mae)\n",
    "        metrics[f'H{h}']['mapes'].append(mape)\n",
    "\n",
    "        # Print the metrics for the current split and horizon\n",
    "        print(f'--- Metrics for Horizon {h} (Time Series Split) ---')\n",
    "        print(f'R²: {r2}')\n",
    "        print(f'RMSE: {rmse}')\n",
    "        print(f'MAE: {mae}')\n",
    "        print(f'MAPE: {mape}%\\n')\n",
    "\n",
    "# Calculate and print average metrics across all splits for each horizon\n",
    "for h in range(1, 4):\n",
    "    average_r2 = np.mean(metrics[f'H{h}']['r2_scores'])\n",
    "    average_rmse = np.mean(metrics[f'H{h}']['rmses'])\n",
    "    average_mae = np.mean(metrics[f'H{h}']['maes'])\n",
    "    average_mape = np.mean(metrics[f'H{h}']['mapes'])\n",
    "\n",
    "    print(f'--- Average Metrics Across All Splits for Horizon {h} ---')\n",
    "    print(f'Average R²: {average_r2}')\n",
    "    print(f'Average RMSE: {average_rmse}')\n",
    "    print(f'Average MAE: {average_mae}')\n",
    "    print(f'Average MAPE: {average_mape}%\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "712ac382-b8f1-4b2b-bff9-595e2f59434c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Baseline for active contract customer for all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f12580d-5900-4af4-8ce9-414d778728ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the relative path to the Dataset folder\n",
    "dataset_path = '../Datasets/df_filtered_active_customers.parquet'\n",
    "\n",
    "# Read DataFrame from Parquet\n",
    "df_filtered_active_customers = pd.read_parquet(dataset_path, engine='pyarrow')\n",
    "print(df_filtered_active_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e031a7f-47ac-4c70-a7a1-236c1e4593d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First test\n",
    "# Sort the data by DATE to ensure proper ordering\n",
    "df_filtered_active_customers.sort_values(by=['DATE', 'CUSTOMER_ID'])\n",
    "\n",
    "# Creating a naive forecast (shifting TOTAL_CONSUMPTION_SUM by 1 to predict next month based on the previous month)\n",
    "df_filtered_active_customers['NAIVE_PREDICTION'] = df_filtered_active_customers.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(1)\n",
    "\n",
    "# Dropping the first row of each customer where no previous data exists for prediction\n",
    "df_naive = df_filtered_active_customers.dropna(subset=['NAIVE_PREDICTION'])\n",
    "\n",
    "# Extract actual values and naive predictions\n",
    "y_true = df_naive['TOTAL_CONSUMPTION_SUM']\n",
    "y_pred = df_naive['NAIVE_PREDICTION']\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Exclude zero actual values for MAPE calculation\n",
    "non_zero_mask = y_true != 0\n",
    "y_true_non_zero = y_true[non_zero_mask]\n",
    "y_pred_non_zero = y_pred[non_zero_mask]\n",
    "\n",
    "# Calculate MAPE (without dividing by zero)\n",
    "mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(f'R²: {r2}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MAPE: {mape}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99925247-f4f2-451c-be05-49f468b5cfbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model for each horizon\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Exclude zero actual values for MAPE calculation\n",
    "    non_zero_mask = y_true != 0\n",
    "    y_true_non_zero = y_true[non_zero_mask]\n",
    "    y_pred_non_zero = y_pred[non_zero_mask]\n",
    "\n",
    "    # Calculate MAPE (without dividing by zero)\n",
    "    mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "\n",
    "    # Return the calculated metrics\n",
    "    return r2, rmse, mae, mape\n",
    "\n",
    "# Initialize dictionaries to store metrics for averaging across horizons\n",
    "metrics = {'H1': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []},\n",
    "           'H2': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []},\n",
    "           'H3': {'r2_scores': [], 'rmses': [], 'maes': [], 'mapes': []}}\n",
    "\n",
    "# Apply naive forecast using TimeSeriesSplit\n",
    "for train_index, test_index in tscv.split(df_filtered_active_customers):\n",
    "    train = df_filtered_active_customers.iloc[train_index].copy()  # Create a copy of the train DataFrame\n",
    "    test = df_filtered_active_customers.iloc[test_index].copy()    # Create a copy of the test DataFrame\n",
    "\n",
    "    # Shift TOTAL_CONSUMPTION_SUM by 1, 2, and 3 to predict next months based on previous months\n",
    "    for h in range(1, 4):\n",
    "        train[f'NAIVE_PREDICTION_H{h}'] = train.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(h)\n",
    "        test[f'NAIVE_PREDICTION_H{h}'] = test.groupby('CUSTOMER_ID')['TOTAL_CONSUMPTION_SUM'].shift(h)\n",
    "\n",
    "    # Evaluate each horizon\n",
    "    for h in range(1, 4):\n",
    "        # Drop rows with NaN predictions\n",
    "        test_naive = test.dropna(subset=[f'NAIVE_PREDICTION_H{h}'])\n",
    "\n",
    "        # Extract true and predicted values for testing\n",
    "        y_true_test = test_naive['TOTAL_CONSUMPTION_SUM']\n",
    "        y_pred_test = test_naive[f'NAIVE_PREDICTION_H{h}']\n",
    "\n",
    "        # Calculate metrics for the current split and horizon\n",
    "        r2, rmse, mae, mape = calculate_metrics(y_true_test, y_pred_test)\n",
    "\n",
    "        # Append metrics to the corresponding horizon lists\n",
    "        metrics[f'H{h}']['r2_scores'].append(r2)\n",
    "        metrics[f'H{h}']['rmses'].append(rmse)\n",
    "        metrics[f'H{h}']['maes'].append(mae)\n",
    "        metrics[f'H{h}']['mapes'].append(mape)\n",
    "\n",
    "        # Print the metrics for the current split and horizon\n",
    "        print(f'--- Metrics for Horizon {h} (Time Series Split) ---')\n",
    "        print(f'R²: {r2}')\n",
    "        print(f'RMSE: {rmse}')\n",
    "        print(f'MAE: {mae}')\n",
    "        print(f'MAPE: {mape}%\\n')\n",
    "\n",
    "# Calculate and print average metrics across all splits for each horizon\n",
    "for h in range(1, 4):\n",
    "    average_r2 = np.mean(metrics[f'H{h}']['r2_scores'])\n",
    "    average_rmse = np.mean(metrics[f'H{h}']['rmses'])\n",
    "    average_mae = np.mean(metrics[f'H{h}']['maes'])\n",
    "    average_mape = np.mean(metrics[f'H{h}']['mapes'])\n",
    "\n",
    "    print(f'--- Average Metrics Across All Splits for Horizon {h} ---')\n",
    "    print(f'Average R²: {average_r2}')\n",
    "    print(f'Average RMSE: {average_rmse}')\n",
    "    print(f'Average MAE: {average_mae}')\n",
    "    print(f'Average MAPE: {average_mape}%\\n')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "naive_forecasting_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
