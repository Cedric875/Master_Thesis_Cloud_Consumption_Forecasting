{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afee7268-cc64-44a5-b4c2-a2915b6ba724",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bbd5f4d-0281-4c48-bb22-9f317c81639d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the relative path to the Dataset folder\n",
    "dataset_path = '../Datasets/df_aggregated_month_populated_btp_core.parquet'\n",
    "\n",
    "# Read DataFrame from Parquet\n",
    "df_aggregated_month_populated_btp_core = pd.read_parquet(dataset_path, engine='pyarrow')\n",
    "print(df_aggregated_month_populated_btp_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom MAPE function that ignores zero values\n",
    "def custom_mape(y_true, y_pred):\n",
    "    # Filter out zero values in y_true to avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    return (np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128ae118-9329-4ffd-96ee-0202dc39d9d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess your data (assuming your data is in the 'df_aggregated_month_populated_btp_core' DataFrame)\n",
    "df_horizon = df_aggregated_month_populated_btp_core.copy()\n",
    "\n",
    "# Define the feature columns to be used for Linear Regression\n",
    "all_features = [\n",
    "    'MONTHLY_CONTRACT_NET_VALUE_SUM',  \n",
    "    'CONTRACT_DURATION_SUM', \n",
    "    'OVERCONSUMPTION_COUNT', \n",
    "    'ORDER_COUNT',  \n",
    "    'TOTAL_CONSUMPTION_LAG_1'\n",
    "]\n",
    "\n",
    "# Get unique customer IDs\n",
    "customer_ids = df_horizon['CUSTOMER_ID'].unique()\n",
    "\n",
    "# Prepare a list to store performance metrics\n",
    "performance_metrics_list = []\n",
    "\n",
    "# Define horizons for forecasting\n",
    "horizons = [1, 2, 3]\n",
    "\n",
    "# Process each customer\n",
    "for customer_id in customer_ids:\n",
    "    print(f\"Processing Customer ID: {customer_id}\")\n",
    "\n",
    "    # Filter data for a specific customer\n",
    "    df_customer = df_horizon[df_horizon['CUSTOMER_ID'] == customer_id]\n",
    "\n",
    "    # Ensure there is enough data for the model (minimum 3 data points per customer)\n",
    "    if len(df_customer) < 3:\n",
    "        continue\n",
    "\n",
    "    # Sort data by 'DATE' to maintain temporal order\n",
    "    df_customer = df_customer.sort_values(by='DATE')\n",
    "\n",
    "    # Initialize metrics storage for each horizon\n",
    "    customer_metrics = {'Customer_ID': customer_id}\n",
    "\n",
    "    # Process each horizon separately\n",
    "    for h in horizons:\n",
    "        # Shift the target variable (TOTAL_CONSUMPTION_SUM) by the horizon\n",
    "        df_customer[f'TOTAL_CONSUMPTION_{h}'] = df_customer['TOTAL_CONSUMPTION_SUM'].shift(-h)\n",
    "        df_customer_filtered = df_customer.dropna(subset=[f'TOTAL_CONSUMPTION_{h}'])  # Drop NaN target values\n",
    "        \n",
    "        # Ensure enough data remains after dropping NaNs\n",
    "        if len(df_customer_filtered) < 3:\n",
    "            continue\n",
    "\n",
    "        # Define X (input features) and y (target) for the current horizon\n",
    "        X = df_customer_filtered[all_features]\n",
    "        y = df_customer_filtered[f'TOTAL_CONSUMPTION_{h}']\n",
    "\n",
    "        # Initialize the Linear Regression model\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # Fit the model on the entire dataset for the current customer\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        # Set negative predictions to 0\n",
    "        y_pred = np.where(y_pred < 0, 0, y_pred)\n",
    "\n",
    "        # Calculate performance metrics for the current horizon\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        mape = custom_mape(y, y_pred)\n",
    "\n",
    "        # Store metrics for the current horizon\n",
    "        customer_metrics[f'MSE_horizon_{h}'] = mse\n",
    "        customer_metrics[f'R²_horizon_{h}'] = r2\n",
    "        customer_metrics[f'MAE_horizon_{h}'] = mae\n",
    "        customer_metrics[f'MAPE_horizon_{h}'] = mape\n",
    "\n",
    "    # Append the customer metrics to the performance list\n",
    "    performance_metrics_list.append(customer_metrics)\n",
    "\n",
    "# Create a DataFrame from the performance metrics list\n",
    "performance_metrics_df = pd.DataFrame(performance_metrics_list)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "performance_metrics_df.to_csv('linear_regression_customer_performance_metrics.csv', index=False)\n",
    "\n",
    "# Calculate and append the averages of the performance metrics **for each horizon**\n",
    "average_metrics_per_horizon = {}\n",
    "for h in horizons:\n",
    "    avg_mse = performance_metrics_df[f'MSE_horizon_{h}'].mean()\n",
    "    avg_r2 = performance_metrics_df[f'R²_horizon_{h}'].mean()\n",
    "    avg_mae = performance_metrics_df[f'MAE_horizon_{h}'].mean()\n",
    "    avg_mape = performance_metrics_df[f'MAPE_horizon_{h}'].mean()\n",
    "\n",
    "    # Store the averages in a dictionary\n",
    "    average_metrics_per_horizon[f'MSE_horizon_{h}'] = avg_mse\n",
    "    average_metrics_per_horizon[f'R²_horizon_{h}'] = avg_r2\n",
    "    average_metrics_per_horizon[f'MAE_horizon_{h}'] = avg_mae\n",
    "    average_metrics_per_horizon[f'MAPE_horizon_{h}'] = avg_mape\n",
    "\n",
    "# Convert the averages dictionary to a DataFrame and add 'Average' label for Customer_ID\n",
    "average_metrics_df = pd.DataFrame([average_metrics_per_horizon])\n",
    "average_metrics_df['Customer_ID'] = 'Average'\n",
    "\n",
    "# Append the averages to the original performance metrics DataFrame and save it\n",
    "performance_metrics_df = performance_metrics_df.append(average_metrics_df, ignore_index=True)\n",
    "performance_metrics_df.to_csv('linear_regression_customer_performance_metrics_with_averages_per_horizon.csv', index=False)\n",
    "\n",
    "print(\"Performance metrics saved to 'linear_regression_customer_performance_metrics_with_averages_per_horizon.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa4cff4-6efa-4716-b834-4a16bf0bf8ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "active contract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86e59015-a9f9-4531-ac9b-455d7f0a206d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the relative path to the Dataset folder\n",
    "dataset_path = '../Datasets/df_filtered_active_customers.parquet'\n",
    "\n",
    "# Read DataFrame from Parquet\n",
    "df_filtered_active_customers = pd.read_parquet(dataset_path, engine='pyarrow')\n",
    "print(df_filtered_active_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b376ff31-9429-41da-8c85-172094c4c610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom MAPE function that ignores zero values\n",
    "def custom_mape(y_true, y_pred):\n",
    "    # Filter out zero values in y_true to avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    return (np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])).mean() * 100\n",
    "\n",
    "# Load and preprocess your data (assuming your data is in the 'df_filtered_active_customers' DataFrame)\n",
    "df_horizon = df_filtered_active_customers.copy()\n",
    "\n",
    "# Define the feature columns to be used for Linear Regression\n",
    "all_features = [\n",
    "    'MONTHLY_CONTRACT_NET_VALUE_SUM',  \n",
    "    'CONTRACT_DURATION_SUM', \n",
    "    'OVERCONSUMPTION_COUNT', \n",
    "    'ORDER_COUNT',  \n",
    "    'TOTAL_CONSUMPTION_LAG_1'\n",
    "]\n",
    "\n",
    "# Get unique customer IDs\n",
    "customer_ids = df_horizon['CUSTOMER_ID'].unique()\n",
    "\n",
    "# Prepare a list to store performance metrics\n",
    "performance_metrics_list = []\n",
    "\n",
    "# Define horizons for forecasting\n",
    "horizons = [1, 2, 3]\n",
    "\n",
    "# Process each customer\n",
    "for customer_id in customer_ids:\n",
    "    print(f\"Processing Customer ID: {customer_id}\")\n",
    "\n",
    "    # Filter data for a specific customer\n",
    "    df_customer = df_horizon[df_horizon['CUSTOMER_ID'] == customer_id]\n",
    "\n",
    "    # Ensure there is enough data for the model (minimum 3 data points per customer)\n",
    "    if len(df_customer) < 3:\n",
    "        continue\n",
    "\n",
    "    # Sort data by 'DATE' to maintain temporal order\n",
    "    df_customer = df_customer.sort_values(by='DATE')\n",
    "\n",
    "    # Initialize metrics storage for each horizon\n",
    "    customer_metrics = {'Customer_ID': customer_id}\n",
    "\n",
    "    # Process each horizon separately\n",
    "    for h in horizons:\n",
    "        # Shift the target variable (TOTAL_CONSUMPTION_SUM) by the horizon\n",
    "        df_customer[f'TOTAL_CONSUMPTION_{h}'] = df_customer['TOTAL_CONSUMPTION_SUM'].shift(-h)\n",
    "        df_customer_filtered = df_customer.dropna(subset=[f'TOTAL_CONSUMPTION_{h}'])  # Drop NaN target values\n",
    "        \n",
    "        # Ensure enough data remains after dropping NaNs\n",
    "        if len(df_customer_filtered) < 3:\n",
    "            continue\n",
    "\n",
    "        # Define X (input features) and y (target) for the current horizon\n",
    "        X = df_customer_filtered[all_features]\n",
    "        y = df_customer_filtered[f'TOTAL_CONSUMPTION_{h}']\n",
    "\n",
    "        # Initialize the Linear Regression model\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # Fit the model on the entire dataset for the current customer\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        # Set negative predictions to 0\n",
    "        y_pred = np.where(y_pred < 0, 0, y_pred)\n",
    "\n",
    "        # Calculate performance metrics for the current horizon\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        mape = custom_mape(y, y_pred)\n",
    "\n",
    "        # Store metrics for the current horizon\n",
    "        customer_metrics[f'MSE_horizon_{h}'] = mse\n",
    "        customer_metrics[f'R²_horizon_{h}'] = r2\n",
    "        customer_metrics[f'MAE_horizon_{h}'] = mae\n",
    "        customer_metrics[f'MAPE_horizon_{h}'] = mape\n",
    "\n",
    "    # Append the customer metrics to the performance list\n",
    "    performance_metrics_list.append(customer_metrics)\n",
    "\n",
    "# Create a DataFrame from the performance metrics list\n",
    "performance_metrics_df = pd.DataFrame(performance_metrics_list)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "performance_metrics_df.to_csv('linear_regression_customer_performance_metrics.csv', index=False)\n",
    "\n",
    "# Calculate and append the averages of the performance metrics **for each horizon**\n",
    "average_metrics_per_horizon = {}\n",
    "for h in horizons:\n",
    "    avg_mse = performance_metrics_df[f'MSE_horizon_{h}'].mean()\n",
    "    avg_r2 = performance_metrics_df[f'R²_horizon_{h}'].mean()\n",
    "    avg_mae = performance_metrics_df[f'MAE_horizon_{h}'].mean()\n",
    "    avg_mape = performance_metrics_df[f'MAPE_horizon_{h}'].mean()\n",
    "\n",
    "    # Store the averages in a dictionary\n",
    "    average_metrics_per_horizon[f'MSE_horizon_{h}'] = avg_mse\n",
    "    average_metrics_per_horizon[f'R²_horizon_{h}'] = avg_r2\n",
    "    average_metrics_per_horizon[f'MAE_horizon_{h}'] = avg_mae\n",
    "    average_metrics_per_horizon[f'MAPE_horizon_{h}'] = avg_mape\n",
    "\n",
    "# Convert the averages dictionary to a DataFrame and add 'Average' label for Customer_ID\n",
    "average_metrics_df = pd.DataFrame([average_metrics_per_horizon])\n",
    "average_metrics_df['Customer_ID'] = 'Average'\n",
    "\n",
    "# Append the averages to the original performance metrics DataFrame and save it\n",
    "performance_metrics_df = performance_metrics_df.append(average_metrics_df, ignore_index=True)\n",
    "performance_metrics_df.to_csv('linear_regression_active_customer_performance_metrics_with_averages_per_horizon.csv', index=False)\n",
    "\n",
    "print(\"Performance metrics saved to 'linear_regression_active_customer_performance_metrics_with_averages_per_horizon.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Linear regression each customer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
